{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom selection of integrations to work with core\n",
    "# pip install llama-index-core\n",
    "# pip install llama-index-llms-openai\n",
    "# pip install llama-index-llms-replicate\n",
    "# pip install replicate\n",
    "# pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RicardoMontaner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.replicate import Replicate\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_EGiIWBdx31PpO5ApNyuEuiW2t8jMueV2LEG1L\"\n",
    "\n",
    "# set the LLM\n",
    "llama2_7b_chat = \"meta/llama-2-7b-chat:8e6975e5ed6174911a6ff3d60540dfd4844201974602551e10e9e87ab143d81e\"\n",
    "Settings.llm = Replicate(\n",
    "  model=llama2_7b_chat,\n",
    "  temperature=0.01,\n",
    "  additional_kwargs={\"top_p\": 1, \"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "# set tokenizer to match LLM\n",
    "Settings.tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n",
    "# set the embed model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' Based on the provided context information, I can determine that the topic of the document is \"Dumm y PDF file\".', source_nodes=[NodeWithScore(node=TextNode(id_='be8f381a-e7bc-4c2c-8992-1db76f13f6c1', embedding=None, metadata={'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1862ad9f-96de-4f6d-ad7c-616c508dd2f8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}, hash='8a6a7b7abf01dfe1967432757f2be37494489a04ddab187bd271f0212e8672c1')}, text='Dumm y PDF file', start_char_idx=0, end_char_idx=15, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5776666683949763)], metadata={'be8f381a-e7bc-4c2c-8992-1db76f13f6c1': {'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read Documents and transform them into vectors\n",
    "documents = SimpleDirectoryReader(\"docs\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "## To query the index\n",
    "query_engine = index.as_query_engine()\n",
    "query_engine.query(\"What is the topic of the document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To store the index in ./storage\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload from disk:\n",
    "\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' As an AI language model, I can analyze the provided context information to determine what has been written in the \"dummy.pdf\" file located at \"c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\". Based on the information provided, there appears to be no text or content written inside the PDF file. Therefore, the answer to the query \"Que hay escrito?\" would be simply \"Nothing.\"', source_nodes=[NodeWithScore(node=TextNode(id_='be8f381a-e7bc-4c2c-8992-1db76f13f6c1', embedding=None, metadata={'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1862ad9f-96de-4f6d-ad7c-616c508dd2f8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}, hash='8a6a7b7abf01dfe1967432757f2be37494489a04ddab187bd271f0212e8672c1')}, text='Dumm y PDF file', start_char_idx=0, end_char_idx=15, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5083451497809096)], metadata={'be8f381a-e7bc-4c2c-8992-1db76f13f6c1': {'page_label': '1', 'file_name': 'dummy.pdf', 'file_path': 'c:\\\\Users\\\\RicardoMontaner\\\\Documents\\\\Mio\\\\Code Python\\\\pyAiLib\\\\docs\\\\dummy.pdf', 'file_type': 'application/pdf', 'file_size': 13264, 'creation_date': '2024-03-11', 'last_modified_date': '2023-05-17'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_engine.query(\"Que hay escrito?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
